[{"content":" The following content is a rough translation by Github Copilot of the original post in Chinese.\nThe goal of Retrohos is to serve as the implementation of the RetroArch Frontend on OpenHarmony/HarmonyOS and to complete the porting of emulator cores from various communities, while also supporting the vision of distributed applications in the Harmony framework (e.g., experiences such as using a large screen display while the phone functions as a controller).\nSince I previously only have rudimentary experience in Android mobile development (controlling Android screen casting via NDK), this log is merely a record of the application development exploration process, not the best implementation, and is for reference only.\nWhat is Libretro RetroArch is a very popular retro gaming console solution. It doesn\u0026rsquo;t provide any emulator functionality itself but acts as an aggregator for community emulators (Emulator Core) and provides a common interface definition, Libretro. The following introduction is generated by ChatGPT:\nLibretro is a lightweight game console emulator core framework. Through the Libretro API, game cores (Core) can be separated from the frontend (Frontend), enabling cross-platform porting of cores and supporting multiple frontends such as RetroArch, Lakka, etc. The Libretro core is a dynamic link library that, through the Libretro API, can initialize game cores, handle input/output, and render audio and video.\nLibretro effectively separates the components of the emulator, allowing us to ignore the implementation of existing frontends (and their different GUI technology stacks) and focus on porting the core and integrating it with the system. Therefore, the goal of the Retrohos project is to implement a frontend compatible with the Libretro API while porting community Emulator Cores, rather than a complete port of RetroArch.\nPreparing the NDK Environment For OpenHarmony development, I recommend using the HarmonyOS commercial release and the developer beta SDK provided by Huawei, rather than the community open-source version of OpenHarmony. Although the two currently have little difference (HarmonyOS Next Beta1 is based on OpenHarmony 5.0.0.xx), the only available and mature ecosystem is HarmonyOS. This is an unavoidable reality.\nFortunately, OpenHarmony NDK development is similar to Android and does not require the official IDE (DevEco Studio). The following development content will be based on command-line tools and performed on a Linux platform (Ubuntu 22.04.3 LTS).\nTaking the latest official Linux version SDK (5.0.0.800) as an example, let\u0026rsquo;s assume the commandline-tools.zip archive has been downloaded and extracted to the $HOME directory. To differentiate version numbers, rename the extracted directory to command-line-tools/5.0.0.800 and create an env.sh file with the following content:\n1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash export OHOS_ROOT=$HOME/command-line-tools/5.0.3.800 export SDK_ROOT=$OHOS_ROOT/sdk/default/openharmony ## export NDK Path export NDK_ROOT=$SDK_ROOT/native export PATH=$NDK_ROOT/build-tools/cmake/bin:$PATH export PATH=$NDK_ROOT/llvm/bin:$PATH ## export OHOS command line tools export PATH=$OHOS_ROOT/tool/node/bin:$PATH export PATH=$OHOS_ROOT/bin:$PATH Afterward, when using it, simply execute source env.sh. This file mainly serves the following purposes:\nSets SDK-related environment variables. The variable names here are not specific requirements, just for easy reference. $NDK_ROOT points to the root directory of the NDK, making it easy to reference the compilation chain tools and link the sysroot. Prepend the paths of cmake and llvm to $PATH, overriding the system\u0026rsquo;s default compilation toolchain to ensure the use of the NDK-provided toolchain. According to the official NDK development documentation, when calling the NDK-provided cmake compiler, the following parameters need to be passed (using aarch64-linux-ohos as an example):\n1 cmake -DOHOS_STL=c++_shared -DOHOS_ARCH=arm64-v8a -DOHOS_PLATFORM=OHOS -DCMAKE_TOOLCHAIN_FILE=${NDK_ROOT}/build/cmake/ohos.toolchain.cmake . Among them, CMAKE_TOOLCHAIN_FILE is the most important, specifying the configuration file of the compilation chain, which will automatically link the sysroot provided by the NDK.\nPorting Libretro Cores Attempting to Port libretro-super The libretro/libretro-super repository is a project for managing Libretro cores and RetroArch compilation scripts on different platforms, organized according to the target triplet identifier. Initially, I thought that OpenHarmony\u0026rsquo;s underlying system was just the Linux kernel\u0026rsquo;s aarch64 architecture, and the dynamic libraries in the toolchain were quite common, unrelated to the SDK. Therefore, I attempted to directly port this super project. Unfortunately, due to the fact that the ohos / OHOS identifiers are not supported by many upstream dependencies and it will not automatically downgrade to the aarch64 Linux build process, a brute-force port would only lead to endless dependency resolution.\nTherefore, the most appropriate solution is to use only the Libretro Core build process (forking repositories one by one for modification ðŸ˜“) and abandon the overall porting of libretro-super, which is too messy. At the start of this project, we focused on porting the ppsspp core: it provides the option to build the ppsspp-libretro dynamic library with few third-party dependencies and was the first core to be successfully built.\nCompiling the ppsspp-libretro Core Building the ppsspp-ffmpeg Static Library The hrydgard/ppsspp repository introduces multiple third-party dependencies through .gitmodules, among which only the hrydgard/ppsspp-ffmpeg maintained by itself requires additional handling to add the OHOS architecture string. Refer to android_arm64_v8a.sh and correspondingly add the content of the ohos_arm64-v8a.sh file as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 #!/bin/bash if [ \u0026#34;$NDK_ROOT\u0026#34; = \u0026#34;\u0026#34; ]; then echo \u0026#34;Please set NDK_ROOT to your OpenHarmony NDK location.\u0026#34; exit 1 fi NDK_PLATFORM=\u0026#34;aarch64-linux-ohos\u0026#34; NDK_PLATFORM_LIB=$NDK_ROOT/sysroot/usr/lib/$NDK_PLATFORM NDK_PREBUILTLLVM=$NDK_ROOT/llvm set -e GENERAL=\u0026#34;\\ --enable-cross-compile \\ --enable-pic \\ --cc=$NDK_PREBUILTLLVM/bin/clang \\ --cross-prefix=$NDK_PREBUILTLLVM/bin/aarch64-unknown-linux-ohos- \\ --ar=$NDK_PREBUILTLLVM/bin/llvm-ar \\ --ld=$NDK_PREBUILTLLVM/bin/clang \\ --nm=$NDK_PREBUILTLLVM/bin/llvm-nm \\ --ranlib=$NDK_PREBUILTLLVM/bin/llvm-ranlib\u0026#34; MODULES=\u0026#34;\\ --disable-avdevice \\ --disable-filters \\ --disable-programs \\ --disable-network \\ --disable-avfilter \\ --disable-postproc \\ --disable-encoders \\ --disable-protocols \\ --disable-hwaccels \\ --disable-doc\u0026#34; VIDEO_DECODERS=\u0026#34;\\ --enable-decoder=h264 \\ --enable-decoder=mpeg4 \\ --enable-decoder=mpeg2video \\ --enable-decoder=mjpeg \\ --enable-decoder=mjpegb\u0026#34; AUDIO_DECODERS=\u0026#34;\\ --enable-decoder=aac \\ --enable-decoder=aac_latm \\ --enable-decoder=atrac3 \\ --enable-decoder=atrac3p \\ --enable-decoder=mp3 \\ --enable-decoder=pcm_s16le \\ --enable-decoder=pcm_s8\u0026#34; DEMUXERS=\u0026#34;\\ --enable-demuxer=h264 \\ --enable-demuxer=m4v \\ --enable-demuxer=mpegvideo \\ --enable-demuxer=mpegps \\ --enable-demuxer=mp3 \\ --enable-demuxer=avi \\ --enable-demuxer=aac \\ --enable-demuxer=pmp \\ --enable-demuxer=oma \\ --enable-demuxer=pcm_s16le \\ --enable-demuxer=pcm_s8 \\ --enable-demuxer=wav\u0026#34; VIDEO_ENCODERS=\u0026#34;\\ --enable-encoder=huffyuv --enable-encoder=ffv1\u0026#34; AUDIO_ENCODERS=\u0026#34;\\ --enable-encoder=pcm_s16le\u0026#34; MUXERS=\u0026#34;\\ --enable-muxer=avi\u0026#34; PARSERS=\u0026#34;\\ --enable-parser=h264 \\ --enable-parser=mpeg4video \\ --enable-parser=mpegaudio \\ --enable-parser=mpegvideo \\ --enable-parser=aac \\ --enable-parser=aac_latm\u0026#34; function build_arm64 { # no-missing-prototypes because of a compile error seemingly unique to aarch64. ./configure --logfile=conflog.txt --target-os=linux \\ --prefix=./ohos/arm64 \\ --arch=aarch64 \\ ${GENERAL} \\ --extra-cflags=\u0026#34; --target=aarch64-linux-ohos -no-canonical-prefixes -fdata-sections -ffunction-sections -fno-limit-debug-info -funwind-tables -fPIC -O2 -DOHOS -DOHOS_ARCH=arm64-v8a -DOHOS_PLATFORM=OHOS -DCMAKE_TOOLCHAIN_FILE=${NDK_ROOT}/build/cmake/ohos.toolchain.cmake -Dipv6mr_interface=ipv6mr_ifindex -fasm -fno-short-enums -fno-strict-aliasing -Wno-missing-prototypes\u0026#34; \\ --disable-shared \\ --enable-static \\ --extra-ldflags=\u0026#34; -B$NDK_PREBUILTLLVM/bin/aarch64-unknown-linux-ohos- --target=aarch64-linux-ohos -Wl,--rpath-link,$NDK_PLATFORM_LIB -L$NDK_PLATFORM_LIB -nostdlib -lc -lm -ldl\u0026#34; \\ --enable-zlib \\ --disable-everything \\ ${MODULES} \\ ${VIDEO_DECODERS} \\ ${AUDIO_DECODERS} \\ ${VIDEO_ENCODERS} \\ ${AUDIO_ENCODERS} \\ ${DEMUXERS} \\ ${MUXERS} \\ ${PARSERS} make clean make -j4 install } build_arm64 After preparing the NDK environment with source env.sh, execute the build script to generate static library files such as libavcodec.a under ohos/arm64, as well as header files under the include directory. After submitting the relevant changes, you can point the submodule in ppsspp-libretro to our modified repository Retrohos/ppsspp-ffmpeg.\nBuilding ppsspp The porting of ppsspp-libretro itself is relatively simple, only requiring the addition of OHOS architecture judgment in CMakeLists.txt and modification of the compilation options in CMakeLists.txt. The patch content is as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 diff --git a/CMakeLists.txt b/CMakeLists.txt index ad2be076b..2fe1e619c 100644 --- a/CMakeLists.txt +++ b/CMakeLists.txt @@ -99,8 +99,12 @@ if(${CMAKE_SYSTEM_NAME} MATCHES \u0026#34;Android\u0026#34;) set(ANDROID ON) endif() +if(${CMAKE_SYSTEM_NAME} MATCHES \u0026#34;OHOS\u0026#34;) +\tset(OHOS ON) +endif() + # We only support Vulkan on Unix, macOS (by MoltenVK), Android and Windows. -if(ANDROID OR WIN32 OR (UNIX AND NOT ARM_NO_VULKAN)) +if(OHOS OR ANDROID OR WIN32 OR (UNIX AND NOT ARM_NO_VULKAN)) set(VULKAN ON) endif() @@ -192,7 +196,7 @@ if(USE_CCACHE) include(ccache) endif() -if(UNIX AND NOT (APPLE OR ANDROID) AND VULKAN) +if(UNIX AND NOT (APPLE OR ANDROID OR OHOS) AND VULKAN) if(USING_X11_VULKAN) message(\u0026#34;Using X11 for Vulkan\u0026#34;) find_package(X11) @@ -225,7 +229,7 @@ if(LIBRETRO) endif() endif() -if(ANDROID) +if(ANDROID OR OHOS) set(MOBILE_DEVICE ON) set(USING_GLES2 ON) endif() @@ -382,7 +386,7 @@ if(NOT MSVC) # NEON optimizations in libpng17 seem to cause PNG load errors, see #14485. add_definitions(-DPNG_ARM_NEON_OPT=0) -\tif(ANDROID) +\tif(ANDROID OR OHOS) set(CMAKE_CXX_FLAGS \u0026#34;${CMAKE_CXX_FLAGS} -std=gnu++17\u0026#34;) endif() if(CLANG) @@ -474,7 +478,7 @@ if(NOT MSVC) if(${CMAKE_SYSTEM_NAME} STREQUAL \u0026#34;NetBSD\u0026#34;) add_definitions(-D_NETBSD_SOURCE) endif() -\telseif(ANDROID) +\telseif(ANDROID OR OHOS) add_definitions(-fsigned-char) endif() else() @@ -943,6 +947,10 @@ if(USE_FFMPEG) elseif(X86) set(PLATFORM_ARCH \u0026#34;android/x86\u0026#34;) endif() +\telseif(OHOS) +\tif(ARM64) +\tset(PLATFORM_ARCH \u0026#34;ohos/arm64\u0026#34;) +\tendif() elseif(IOS) if(IOS_PLATFORM STREQUAL \u0026#34;TVOS\u0026#34;) set(PLATFORM_ARCH \u0026#34;tvos/arm64\u0026#34;) @@ -1200,7 +1208,7 @@ else() endif() # Arm platforms require at least libpng17. -if(ANDROID OR ARMV7 OR ARM64 OR ARM OR IOS) +if(OHOS OR ANDROID OR ARMV7 OR ARM64 OR ARM OR IOS) set(PNG_REQUIRED_VERSION 1.7) else() set(PNG_REQUIRED_VERSION 1.6) After modifying, execute the following command to build the ppsspp-libretro core:\n1 cmake -DOHOS_STL=c++_shared -DOHOS_ARCH=arm64-v8a -DOHOS_PLATFORM=OHOS -DCMAKE_TOOLCHAIN_FILE=${NDK_ROOT}/build/cmake/ohos.toolchain.cmake -DLIBRETRO=ON -DUSING_EGL=ON -DUSING_GLES2=ON . -Bbuild which will generate the build directory, and execute make -j4 within it to generate the lib/ppsspp_libretro.so file.\nFuture Plans As the project\u0026rsquo;s initial stage, the completion of a core port is sufficient for subsequent frontend development. The next step is to design a simple Libretro frontend and bind it through ArkTS NAPI to quickly implement framebuffer output. As for more important GUI design, we can wait for the improvement of the DevEco Studio development suite (ï½žoï¿£3ï¿£)ï½ž\n","date":"2024-09-07T22:14:46+08:00","image":"https://sudofree.xyz/en/p/retrohos-development-logs-01-migrating-libretro-cores/ppsspp-libretro-core_hu15084682474071154973.png","permalink":"https://sudofree.xyz/en/p/retrohos-development-logs-01-migrating-libretro-cores/","title":"Retrohos Development Log #1: Migrating Libretro Cores"},{"content":"I wonder why there is no issue identify the memory leak problem. Maybe I am too lazy to look for it thoroughly on the internet. Anyway, I found there is an apparent memory leak problem in the original implementation (the source code is available on Github).\nI find the problem when I am working on loading a large dataset with around $600$ images and $4$ million points, jointly collected with accurate geometry mapping. And it simply takes up 20GB+ memory on the NVIDIA RTX 3090 GPU, and 15GB+ memory at the same time. While the scene is large indeed, I am curious why it takes up all the memory at the start, but not increasing w.r.t the training process!\nThe First Patch - Lazy Loading Firstly, I identify the cause of huge memory footprint on CPU (i.e., RAM usage): all the images are loaded in RAM with corresponding tensors on GPU. The related source code is in utils/camera_utils.py#L20:\n1 2 3 4 5 6 7 8 9 def loadCam(args, id, cam_info, resolution_scale, is_test_dataset): ... return Camera(resolution, colmap_id=cam_info.uid, R=cam_info.R, T=cam_info.T, FoVx=cam_info.FovX, FoVy=cam_info.FovY, depth_params=cam_info.depth_params, image=image, invdepthmap=invdepthmap, image_name=cam_info.image_name, uid=id, data_device=args.data_device, train_test_exp=args.train_test_exp, is_test_dataset=is_test_dataset, is_test_view=cam_info.is_test) My immediate thought is to do the tradeoff: the image loading time may not deserve so much memory consumption, especially considering the following up huge training burden. Therefore, I compose a LazyLoader class to delay the instainiation of Camera class until the first reference. The example implementation is below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from scene.cameras import Camera class LazyLoader: def __init__(self, cls, *args, **kwargs): self.cls = cls self.args = args self.kwargs = kwargs self.instance = None pass def __getattribute__(self, name: str): if name in [\u0026#39;cls\u0026#39;, \u0026#39;args\u0026#39;, \u0026#39;kwargs\u0026#39;, \u0026#39;instance\u0026#39;]: return super().__getattribute__(name) else: if not self.instance: self.instance = self.cls(*self.args, **self.kwargs) return getattr(self.instance, name) def __del__(self): if self.instance: del self.instance pass pass The original reference of Camera class build is therefore revised as:\n1 2 - return Camera(colmap_id=cam_info.uid, R=cam_info.R, T=cam_info.T, + return LazyLoader(Camera, colmap_id=cam_info.uid, R=cam_info.R, T=cam_info.T, And after the usage in the main training loop in train.py, the image could be immediately deleted, until created at the next usage.\n1 2 3 4 5 6 # Loss gt_image = viewpoint_cam.original_image.cuda() + del viewpoint_cam Ll1 = l1_loss(image, gt_image) loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(image, gt_image)) loss.backward() However, the weird thing is, the memory usage does start with an acceptable amount at the start with image loading one-by-one as expected. But it finally grows up to 20GB+ and then never decreases. So I realized the real problem here is, the memory leak.\nThe Second Patch - Memory Leak Fix The memory leak here is very confusing. As I mentioned before, I use del to remove the reference to the Camera class in Python, and all the held memory should be wiped out at the same time. I have tried to search for the cause everywhere but only to find out it is related to PyTorch. Since I could not dig into the CUDA tensor things, I started to try to del everything related in Python code. Luckily, it turns out to work.\nThe patch could be broken down into two parts. The first part is to improve the efficiency of image loading:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 diff --git a/scene/__init__.py b/scene/__init__.py --- a/scene/__init__.py +++ b/scene/__init__.py @@ -37,9 +37,6 @@ class Scene: self.loaded_iter = load_iteration print(\u0026#34;Loading trained model at iteration {}\u0026#34;.format(self.loaded_iter)) - self.train_cameras = {} - self.test_cameras = {} - if os.path.exists(os.path.join(args.source_path, \u0026#34;sparse\u0026#34;)): scene_info = sceneLoadTypeCallbacks[\u0026#34;Colmap\u0026#34;](args.source_path, args.images, args.eval) elif os.path.exists(os.path.join(args.source_path, \u0026#34;transforms_train.json\u0026#34;)): @@ -67,12 +64,8 @@ class Scene: random.shuffle(scene_info.test_cameras) # Multi-res consistent random shuffling self.cameras_extent = scene_info.nerf_normalization[\u0026#34;radius\u0026#34;] - - for resolution_scale in resolution_scales: - print(\u0026#34;Loading Training Cameras\u0026#34;) - self.train_cameras[resolution_scale] = cameraList_from_camInfos(scene_info.train_cameras, resolution_scale, args) - print(\u0026#34;Loading Test Cameras\u0026#34;) - self.test_cameras[resolution_scale] = cameraList_from_camInfos(scene_info.test_cameras, resolution_scale, args) + self.scene_info = scene_info + self.args = args if self.loaded_iter: self.gaussians.load_ply(os.path.join(self.model_path, @@ -87,7 +80,7 @@ class Scene: self.gaussians.save_ply(os.path.join(point_cloud_path, \u0026#34;point_cloud.ply\u0026#34;)) def getTrainCameras(self, scale=1.0): - return self.train_cameras[scale] + return cameraList_from_camInfos(self.scene_info.train_cameras, scale, self.args) def getTestCameras(self, scale=1.0): - return self.test_cameras[scale] \\ No newline at end of file + return cameraList_from_camInfos(self.scene_info.test_cameras, scale, self.args) \\ No newline at end of file diff --git a/scene/cameras.py b/scene/cameras.py --- a/scene/cameras.py +++ b/scene/cameras.py @@ -17,6 +17,7 @@ from utils.graphics_utils import getWorld2View2, getProjectionMatrix class Camera(nn.Module): def __init__(self, colmap_id, R, T, FoVx, FoVy, image, gt_alpha_mask, image_name, uid, + raw_image=None, trans=np.array([0.0, 0.0, 0.0]), scale=1.0, data_device = \u0026#34;cuda\u0026#34; ): super(Camera, self).__init__() @@ -29,6 +30,14 @@ class Camera(nn.Module): self.FoVy = FoVy self.image_name = image_name + if raw_image is not None: + image = raw_image[:3, ...] + gt_alpha_mask = None + + if raw_image.shape[1] == 4: + gt_alpha_mask = raw_image[3:4, ...] + del raw_image + try: self.data_device = torch.device(data_device) except Exception as e: @@ -39,9 +48,11 @@ class Camera(nn.Module): self.original_image = image.clamp(0.0, 1.0).to(self.data_device) self.image_width = self.original_image.shape[2] self.image_height = self.original_image.shape[1] + del image if gt_alpha_mask is not None: self.original_image *= gt_alpha_mask.to(self.data_device) + del gt_alpha_mask else: self.original_image *= torch.ones((1, self.image_height, self.image_width), device=self.data_device) @@ -56,6 +67,9 @@ class Camera(nn.Module): self.full_proj_transform = (self.world_view_transform.unsqueeze(0).bmm(self.projection_matrix.unsqueeze(0))).squeeze(0) self.camera_center = self.world_view_transform.inverse()[3, :3] + def __del__(self): + del self.original_image, self.world_view_transform, self.projection_matrix, self.full_proj_transform, self.camera_center + class MiniCam: def __init__(self, width, height, fovy, fovx, znear, zfar, world_view_transform, full_proj_transform): self.image_width = width diff --git a/train.py b/train.py --- a/train.py +++ b/train.py @@ -44,103 +43,82 @@ def training(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoi iter_start = torch.cuda.Event(enable_timing = True) iter_end = torch.cuda.Event(enable_timing = True) - viewpoint_stack = None + viewpoint_stack = scene.getTrainCameras() ema_loss_for_log = 0.0 progress_bar = tqdm(range(first_iter, opt.iterations), desc=\u0026#34;Training progress\u0026#34;) first_iter += 1 The second part is to use del in the main training loop. Since I have done other modification to the training procedure, I could not give the complete patch here. A reduced version is shown below.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 for iteration in range(first_iter, opt.iterations + 1): iter_start.record() gaussians.update_learning_rate(iteration) # Every 1000 its we increase the levels of SH up to a maximum degree if iteration % 1000 == 0: gaussians.oneupSHdegree() # Pick a random Camera if len(viewpoint_stack)==0: del viewpoint_stack viewpoint_stack = scene.getTrainCameras() viewpoint_cam = viewpoint_stack.pop(randint(0, len(viewpoint_stack)-1)) # Render if (iteration - 1) == debug_from: pipe.debug = True bg = torch.rand((3), device=\u0026#34;cuda\u0026#34;) if opt.random_background else background render_pkg = render(viewpoint_cam, gaussians, pipe, bg) image, viewspace_point_tensor, visibility_filter, radii = render_pkg[\u0026#34;render\u0026#34;], render_pkg[\u0026#34;viewspace_points\u0026#34;], render_pkg[\u0026#34;visibility_filter\u0026#34;], render_pkg[\u0026#34;radii\u0026#34;] # Loss gt_image = viewpoint_cam.original_image.cuda() Ll1 = l1_loss(image, gt_image) loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(image, gt_image)) loss.backward() iter_end.record() with torch.no_grad(): # Progress bar ema_loss_for_log = 0.4 * loss.item() + 0.6 * ema_loss_for_log if iteration % 10 == 0: progress_bar.set_postfix({\u0026#34;Loss\u0026#34;: f\u0026#34;{ema_loss_for_log:.{7}f}\u0026#34;}) progress_bar.update(10) if iteration == opt.iterations: progress_bar.close() # Log and save torch.cuda.empty_cache() if (iteration in saving_iterations): print(\u0026#34;\\n[ITER {}] Saving Gaussians\u0026#34;.format(iteration)) scene.save(iteration) # Densification if iteration \u0026lt; opt.densify_until_iter: # Keep track of max radii in image-space for pruning gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter]) gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter) if iteration \u0026gt; opt.densify_from_iter and iteration % opt.densification_interval == 0: size_threshold = 20 if iteration \u0026gt; opt.opacity_reset_interval else None gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, scene.cameras_extent, size_threshold) if iteration % opt.opacity_reset_interval == 0 or (dataset.white_background and iteration == opt.densify_from_iter): gaussians.reset_opacity() # Optimizer step if iteration \u0026lt; opt.iterations: gaussians.optimizer.step() gaussians.optimizer.zero_grad(set_to_none = True) if (iteration in checkpoint_iterations): print(\u0026#34;\\n[ITER {}] Saving Checkpoint\u0026#34;.format(iteration)) torch.save((gaussians.capture(), iteration), scene.model_path + \u0026#34;/chkpnt\u0026#34; + str(iteration) + \u0026#34;.pth\u0026#34;) del viewpoint_cam, image, viewspace_point_tensor, visibility_filter, radii, gt_image, Ll1, loss, render_pkg After the two patches, the memory usage is finally under control. The GPU memory usage could be kept under 10GB in our case.\nConclusion I am not sure whether I should report the issue to the original repository. Since people are not aware of the memory leak problem in the past year, I am not sure whether it is a common problem or just a problem in my case. Anyway, I hope this post could help someone who is struggling with the same problem.\n","date":"2024-09-02T15:43:01+08:00","image":"https://sudofree.xyz/en/p/solve-memory-leak-in-vanilla-gaussian-splatting-code/memory-leak_hu14931053131067599422.png","permalink":"https://sudofree.xyz/en/p/solve-memory-leak-in-vanilla-gaussian-splatting-code/","title":"Solve Memory Leak in Vanilla Gaussian Splatting Code"}]